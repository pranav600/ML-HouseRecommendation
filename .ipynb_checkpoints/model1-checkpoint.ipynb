{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de149d12-65c8-4001-ad98-e66a03eaa828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Before Hyperparameter Tuning:\n",
      "                         MAE       MSE      RMSE        R²      MAPE\n",
      "Random Forest      0.400469  0.305992  0.553166  0.778040  0.025780\n",
      "Gradient Boosting  0.407396  0.300341  0.548033  0.782140  0.026280\n",
      "Extra Trees        0.411447  0.330871  0.575214  0.759994  0.026473\n",
      "KNN                0.413308  0.326580  0.571472  0.763107  0.026595\n",
      "SVR                0.407495  0.329957  0.574419  0.760657  0.026358\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Makaan_Properties_No_Duplicates.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Data Cleaning\n",
    "data[\"Size\"] = data[\"Size\"].str.replace(\",\", \"\").str.extract(r\"(\\d+)\").astype(float)\n",
    "data[\"No_of_BHK\"] = data[\"No_of_BHK\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "data[\"Price\"] = data[\"Price\"].str.replace(\",\", \"\", regex=True).astype(float)\n",
    "\n",
    "# Log transformation to reduce skewness\n",
    "data[\"Price\"] = np.log1p(data[\"Price\"])\n",
    "\n",
    "# Feature Engineering\n",
    "features = [\"Size\", \"No_of_BHK\", \"City_name\", \"Property_type\"]\n",
    "target = \"Price\"\n",
    "\n",
    "numerical_cols = [\"Size\", \"No_of_BHK\"]\n",
    "categorical_cols = [\"City_name\", \"Property_type\"]\n",
    "\n",
    "# Handle missing values\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "# One-Hot Encoding for categorical variables\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Polynomial Features (degree=2 for better feature interaction)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", Pipeline([(\"imputer\", num_imputer), (\"poly\", poly), (\"scaler\", scaler)]), numerical_cols),\n",
    "    (\"cat\", Pipeline([(\"imputer\", cat_imputer), (\"encoder\", encoder)]), categorical_cols)\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestRegressor(n_jobs=-1, random_state=42, bootstrap=True, oob_score=True, criterion=\"squared_error\"),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesRegressor(n_estimators=200, max_depth=30, n_jobs=-1, random_state=42),\n",
    "    \"KNN\": KNeighborsRegressor(n_neighbors=7, weights='distance'),\n",
    "    \"SVR\": SVR(kernel=\"rbf\", C=150, epsilon=0.05)\n",
    "}\n",
    "\n",
    "# Train models and evaluate performance\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    results[model_name] = {\n",
    "        \"MAE\": mean_absolute_error(y_test, y_pred),\n",
    "        \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"R²\": r2_score(y_test, y_pred),\n",
    "        \"MAPE\": mean_absolute_percentage_error(y_test, y_pred),\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Before Hyperparameter Tuning:\\n\", results_df)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "param_grid_rf = {\n",
    "    \"model__n_estimators\": [400, 800, 1200, 1500],\n",
    "    \"model__max_depth\": [10, 30, 50, None],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4],\n",
    "   \"model__max_features\": [\"sqrt\", \"log2\", None],\n",
    "    \"model__bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    Pipeline([(\"preprocessor\", preprocessor), (\"model\", RandomForestRegressor(n_jobs=-1, random_state=42))]),\n",
    "    param_distributions=param_grid_rf,\n",
    "    n_iter=30,  # Testing 30 random parameter combinations\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the tuned Random Forest model\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "tuned_rf = random_search_rf.best_estimator_\n",
    "\n",
    "# Predict with tuned model\n",
    "y_pred_rf = tuned_rf.predict(X_test)\n",
    "\n",
    "# Update results with tuned Random Forest model\n",
    "results_df.loc[\"Tuned Random Forest\"] = {\n",
    "    \"MAE\": mean_absolute_error(y_test, y_pred_rf),\n",
    "    \"MSE\": mean_squared_error(y_test, y_pred_rf),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_rf)),\n",
    "    \"R²\": r2_score(y_test, y_pred_rf),\n",
    "    \"MAPE\": mean_absolute_percentage_error(y_test, y_pred_rf),\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Results After Hyperparameter Tuning:\\n\", results_df)\n",
    "\n",
    "# Accuracy Comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=results_df.index, y=results_df[\"R²\"], palette=\"viridis\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"R² Score (Accuracy)\")\n",
    "plt.title(\"Model Accuracy Comparison (R² Score)\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb387deb-4eb8-4100-9fb5-d4b492e91822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
